{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "gpuClass": "premium",
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "kwargs = {\n",
    "    \"seed\": 43,\n",
    "    \"data_dir\": \"data/\",\n",
    "    \"train_dir\": \"outputs/\",\n",
    "    \"epoch\": 16,\n",
    "    \"learning_rate\": 1e-5,\n",
    "    \"batch_size\": 6,\n",
    "    \"do_train\": True,\n",
    "    \"checkpoint\": \"google/pegasus-cnn_dailymail\",\n",
    "    \"max_output_length\": 350,\n",
    "    \"revision\": \"main\",\n",
    "    \"output_dir\": \"outputs/D5_evaltest\",\n",
    "    \"dataset_type\": \"validation\",\n",
    "}"
   ],
   "metadata": {
    "id": "Hy44Z2jRgKn3"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mutm3MzTMrql"
   },
   "outputs": [],
   "source": [
    "!pip install datasets\n",
    "!pip install transformers\n",
    "!pip install route_score\n",
    "!pip install evaluate\n",
    "!pip install rouge_score\n",
    "!pip install sentencepiece\n",
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ],
   "metadata": {
    "id": "vtM60WGlKVjd"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!python -m torch.utils.collect_env"
   ],
   "metadata": {
    "id": "NAJ77sWzFFED"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, Seq2SeqTrainingArguments, AutoModelForSeq2SeqLM, AutoConfig, DataCollatorForSeq2Seq, \\\n",
    "    Seq2SeqTrainer\n",
    "import evaluate\n",
    "from datasets import load_dataset, DatasetDict, concatenate_datasets\n",
    "import json\n",
    "from rouge_score import rouge_scorer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk import download"
   ],
   "metadata": {
    "id": "RW0s1l__M_iA"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "download('punkt')"
   ],
   "metadata": {
    "id": "s9kqZPnKyWvq"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = load_dataset('json', data_files='dataset.json', field=\"train\", split=\"train\")\n",
    "eval_dataset = load_dataset('json', data_files='dataset.json', field=\"validation\", split=\"train\")\n",
    "test_dataset = load_dataset('json', data_files='dataset.json', field=\"test\", split=\"train\")"
   ],
   "metadata": {
    "id": "zEzeKUmLhxGV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ds = DatasetDict({\"train\":train_dataset,\"test\":test_dataset, \"validation\":eval_dataset})\n",
    "ds"
   ],
   "metadata": {
    "id": "nDv_BJ6hiHnK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    kwargs[\"checkpoint\"],\n",
    "    mask_token_sent=\"[MASK]\",\n",
    "    revision=kwargs[\"revision\"],\n",
    "    )\n",
    "\n",
    "\n",
    "def tokenize__data(data):\n",
    "    input_feature = tokenizer(data[\"text\"], truncation=True, padding=True, max_length=1024)\n",
    "    label = tokenizer(data[\"summary\"], truncation=True, padding=True, max_length=kwargs[\"max_output_length\"])\n",
    "    return {\n",
    "        \"input_ids\": input_feature[\"input_ids\"],\n",
    "        \"attention_mask\": input_feature[\"attention_mask\"],\n",
    "        \"labels\": label[\"input_ids\"],\n",
    "    }"
   ],
   "metadata": {
    "id": "BbTo03EYOgkD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "ds_for_train = ds.map(\n",
    "    tokenize__data,\n",
    "    remove_columns=[\"id\", \"summary\", \"text\"],\n",
    "    batched=True,\n",
    "    batch_size=kwargs[\"batch_size\"])\n",
    "ds_for_train"
   ],
   "metadata": {
    "id": "rk0SLlBwf8XF"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Check GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ],
   "metadata": {
    "id": "Mge8GxApf_aV"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "config = AutoConfig.from_pretrained(\n",
    "    kwargs[\"checkpoint\"],\n",
    "    max_length=kwargs[\"max_output_length\"],\n",
    "    revision=kwargs[\"revision\"],\n",
    ")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    kwargs[\"checkpoint\"],\n",
    "    revision=kwargs[\"revision\"],\n",
    "    config=config)\n",
    "model.resize_token_embeddings(len(tokenizer.vocab))"
   ],
   "metadata": {
    "id": "15jdHBstgB6s"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "model.to(device)"
   ],
   "metadata": {
    "id": "W-4mPCWdgZcW"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model, return_tensors=\"pt\")\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=kwargs[\"train_dir\"],\n",
    "    seed=kwargs[\"seed\"],\n",
    "    overwrite_output_dir=True,\n",
    "    label_names=[\"labels\"],\n",
    "    num_train_epochs=kwargs[\"epoch\"],\n",
    "    per_device_train_batch_size=kwargs[\"batch_size\"],\n",
    "    per_device_eval_batch_size=kwargs[\"batch_size\"],\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"rouge1\",\n",
    "    generation_max_length = kwargs[\"max_output_length\"],\n",
    "    predict_with_generate=True,\n",
    "    save_total_limit=1,\n",
    ")\n",
    "\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "\n",
    "def tokenize_sentence(arg):\n",
    "    encoded_arg = tokenizer(arg)\n",
    "    return tokenizer.convert_ids_to_tokens(encoded_arg.input_ids)\n",
    "\n",
    "\n",
    "def get_pred_label(predictions, labels):\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "\n",
    "    predictions = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    print(predictions)\n",
    "    print(labels)\n",
    "\n",
    "    text_predicitons = [\" \\n \".join(sent_tokenize(p.replace(\"<n>\", \" \\n \"))) for p in predictions]\n",
    "    text_labels = [\" \\n \".join(sent_tokenize(l)) for l in labels]\n",
    "\n",
    "\n",
    "    print(text_predicitons)\n",
    "    print(text_labels)\n",
    "    return text_predicitons, text_labels\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    predictions, labels = eval_preds\n",
    "    predictions, labels = get_pred_label(predictions, labels)\n",
    "    return rouge_metric.compute(predictions=predictions, references=labels, tokenizer=tokenize_sentence)\n",
    "\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=ds_for_train[\"train\"],\n",
    "    eval_dataset=ds_for_train[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ],
   "metadata": {
    "id": "VcJlw58jgf_C"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "torch.cuda.empty_cache()\n",
    "if kwargs[\"do_train\"]:\n",
    "    trainer.train()\n",
    "    trainer.save_model()"
   ],
   "metadata": {
    "id": "KllkHtpTgiHe"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "if kwargs[\"do_train\"]:\n",
    "    model.push_to_hub(\"junyinc/LING-575-WI-SUM\")\n",
    "    tokenizer.push_to_hub(\"junyinc/LING-575-WI-SUM\")"
   ],
   "metadata": {
    "id": "A3mNjzLsGVMD"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(kwargs[\"dataset_type\"])\n",
    "final_validation_predictions = trainer.predict(ds_for_train[kwargs[\"dataset_type\"]])"
   ],
   "metadata": {
    "id": "NESRLxuyr8CE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from pathlib import Path\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "output_dir_path = kwargs[\"output_dir\"]\n",
    "Path(output_dir_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "validation_predictions, validation_labels, validation_metrics = final_validation_predictions\n",
    "\n",
    "print(validation_metrics)\n",
    "\n",
    "predictions, labels = get_pred_label(validation_predictions, validation_labels)\n",
    "\n",
    "ids = test_dataset[\"id\"]\n",
    "\n",
    "if kwargs[\"dataset_type\"] == \"validation\":\n",
    "  ids = eval_dataset[\"id\"]\n",
    "\n",
    "for i in range(0, len(ids)):\n",
    "  print(\"***** Summary Text (Gold Text) *****\")\n",
    "  print(labels[i])\n",
    "  print(\"***** Summary Text (Generated Text) *****\")\n",
    "  print(predictions[i])\n",
    "\n",
    "  with open(\"{}/{}-A.M.100.{}.3\".format(output_dir_path, ids[i][:-1], ids[i][-1]), \"w\") as output_file:\n",
    "    output_file.write(predictions[i])\n"
   ],
   "metadata": {
    "id": "mBvdXOTVMh6i"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!zip -r /content/output_dev.zip /content/outputs/D5_devtest"
   ],
   "metadata": {
    "id": "6zSMt331Pz-0"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!zip -r /content/output_eval.zip /content/outputs/D5_evaltest"
   ],
   "metadata": {
    "id": "7PBwvJILlKAt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import files\n",
    "files.download(\"/content/output_dev.zip\")\n",
    "files.download(\"/content/output_eval.zip\")"
   ],
   "metadata": {
    "id": "yUtxTD71P9nR"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
